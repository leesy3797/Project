import streamlit as st
from dotenv import load_dotenv
from loguru import logger
from langchain.memory import ConversationBufferMemory
from google import generativeai as genai
import os
from langsmith import Client
from langchain.callbacks.base import BaseCallbackHandler
from langchain_core.runnables import RunnableConfig
from langchain_core.tracers import LangChainTracer
from langchain_core.tracers.run_collector import RunCollectorCallbackHandler
from utils import *
from langchain.callbacks.tracers.langchain import wait_for_all_tracers
import time
from streamlit_feedback import streamlit_feedback


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ì™€ ëª¨ë¸ ì •ë³´
GEMINI_MODEL = 'gemini-1.5-flash-latest'
GOOGLE_API_KEY = os.environ["GOOGLE_API_KEY"]
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
WELCOME_MESSAGE = "ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì–´ì§„ ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ì£¼ì„¸ìš”!"


# os.environ["LANGCHAIN_PROJECT"] = st.secrets["LANGCHAIN_PROJECT"]
# os.environ["LANGCHAIN_API_KEY"] = st.secrets["LANGCHAIN_API_KEY"]
logger.info(f"Langchain Project : {os.environ["LANGSMITH_PROJECT"]}")
logger.info(f"Langchain API : {os.environ["LANGSMITH_API_KEY"]}")

# Google AI ì„¤ì •
genai.configure(api_key=GOOGLE_API_KEY)

st.set_page_config(
    page_title="Document Assistant V1",
    page_icon=":mag:",
    layout="centered",
    # layout='wide',
    initial_sidebar_state="auto",
    menu_items={
        'About': "# :green[ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì‚´]ì…ë‹ˆë‹¤.\n ë¬¸ì„œ ê¸°ë°˜ì˜ **AI ì±—ë´‡**ìœ¼ë¡œ ë‹¹ì‹ ì˜ ê¶ê¸ˆì¦ì„ í•´ì†Œí•˜ì„¸ìš”!"
    }
)

st.title("ğŸ¤– ë„íë¨¼íŠ¸ ì–´ì‹œìŠ¤í„´íŠ¸ (with Naive RAG) âœ¨")
st.subheader("Ask Anything to Me! ğŸ’¡ğŸ”®")

if "conversation" not in st.session_state:
    st.session_state.conversation = None

if "chat_history" not in st.session_state:
    st.session_state.chat_history = None

if "processComplete" not in st.session_state:
    st.session_state.processComplete = None

if "retriever" not in st.session_state:
    st.session_state.retriever = None

if "messages" not in st.session_state:
    st.session_state.messages = []

if "langsmith_api_key" not in st.session_state:
    st.session_state.langsmith_api_key = os.environ["LANGSMITH_API_KEY"]

if "memory" not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)


def check_if_key_exists(key):
    return key in st.session_state

if not check_if_key_exists("langsmith_api_key"):
    st.info(
        "âš ï¸ [LangSmith API Key](https://docs.smith.langchain.com/observability#2-create-an-api-key)ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”."
    )
else:
    # langchain_endpoint = st.secrets["LANGCHAIN_ENDPOINT"]
    langsmith_endpoint = os.environ["LANGSMITH_ENDPOINT"]

    client = Client(
        api_url = langsmith_endpoint, 
        api_key = st.session_state["langsmith_api_key"]
    )
    ls_tracer = LangChainTracer(
        # project_name=st.secrets["LANGCHAIN_PROJECT"],
        project_name=os.environ["LANGSMITH_PROJECT"],

        client=client
        )
    run_collector = RunCollectorCallbackHandler()
    cfg = RunnableConfig()
    cfg["callbacks"] = [ls_tracer, run_collector]

if not check_if_key_exists("google_api_key"):
    st.info(
       "âš ï¸ [Google API key](https://platform.openai.com/docs/guides/authentication) ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”." 
    )  

with st.sidebar:
    st.header("ì„¤ì •")
    
    uploaded_files = st.file_uploader(
        "ë„íë¨¼íŠ¸ íŒŒì¼ ì—…ë¡œë“œ",
        type=['pdf', 'docx', "pptx", "hwp", "hwpx"],
        accept_multiple_files=True,
    )
    
    google_api_key = None
    openai_api_key = None

    selected_model = st.selectbox(
        "ì±—ë´‡ ëª¨ë¸ ì„ íƒ",
        [None, "Gemini-1.5-Pro", "Gemini-1.5-Flash", "GPT-4o-mini", "Llama3"],
        format_func=lambda x: "ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”" if x is None else x
    )

    if (selected_model in ["Gemini-1.5-Pro", "Gemini-1.5-Flash"]) and (not google_api_key):
        google_api_key = st.text_input(
            "Google API Key",
            type="password",
            value=GOOGLE_API_KEY
        )
        if "google_api_key" not in st.session_state:
            st.session_state["google_api_key"] = google_api_key

    elif (selected_model in ["GPT-4o-mini"]) and (not openai_api_key):
        openai_api_key = st.text_input(
            "OpenAI API Key",
            key="openai_model_api_key",
            type="password",
            value = OPENAI_API_KEY
        )
        if "openai_api_key" not in st.session_state:
            st.session_state["openai_api_key"] = openai_api_key

    if google_api_key or openai_api_key or (selected_model == "Llama3"):

        selected_embedding_model = st.selectbox(
            "ì„ë² ë”© ëª¨ë¸ ì„ íƒ",
            [None, "GoogleEmbedding", "OpenAIEmbedding", "ko-sroberta-multitask"],
            format_func=lambda x: "ì„ë² ë”©ì„ ì„ íƒí•˜ì„¸ìš”" if x is None else x
        )
        if selected_embedding_model:
            if selected_embedding_model == "GoogleEmbedding" and not google_api_key:
                google_api_key = st.text_input(
                    "Google API Key",
                    type="password",
                    value=GOOGLE_API_KEY
                )
                if "google_api_key" not in st.session_state:
                    st.session_state["google_api_key"] = google_api_key

            elif selected_embedding_model == "OpenAIEmbedding" and not openai_api_key:
                openai_api_key = st.text_input(
                    "OpenAI API Key",
                    type="password",
                    value = OPENAI_API_KEY
                )
                if "openai_api_key" not in st.session_state:
                    st.session_state["openai_api_key"] = openai_api_key

    process = st.button("ì„¤ì • ì™„ë£Œ")
 

    reset_history = st.button("ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™”", type="primary")

    if reset_history:
        st.session_state.messages = []
        st.session_state["last_run"] = None

    api_keys = {
        "google_api_key": google_api_key,
        "openai_api_key": openai_api_key
    }

# Process ë²„íŠ¼ì„ ëˆ„ë¥¼ ë•Œ API í‚¤ ìœ íš¨ì„± ê²€ì¦
if process:
    # st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": WELCOME_MESSAGE})
    
    check_api_keys(selected_model, selected_embedding_model, openai_api_key, google_api_key)

    with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
        files_text = get_text(uploaded_files)
        text_chunks = get_text_chunks(files_text)
        vectorstore = get_vectorstore(text_chunks, selected_embedding_model, api_keys)
        st.session_state.conversation, st.session_state.retriever = create_rag_chain(text_chunks, vectorstore, selected_model, api_keys)
        st.session_state.processComplete = True 

    with st.chat_message("assistant"):
        typing_area = st.empty()  # ë¹ˆ ê³µê°„ì„ ë§Œë“¤ì–´ì„œ í…ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•  ì¤€ë¹„
        typing_text = ""
        for char in WELCOME_MESSAGE:
            typing_text += char
            typing_area.markdown(typing_text)  # í˜„ì¬ê¹Œì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥
            time.sleep(0.02)  # ê° ê¸€ìë¥¼ ì¶œë ¥í•  ë•Œë§ˆë‹¤ ì•½ê°„ì˜ ì§€ì—° (0.05ì´ˆ)
        st.rerun()
    
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Chat logic
if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": query})

    with st.chat_message("user"):
        st.markdown(query)

    with st.chat_message("assistant"):
        chain = st.session_state.conversation
        retriever = st.session_state.retriever

        with st.spinner("ìƒê°ì¤‘..."):
            memory = st.session_state.memory
            retrieved_docs = retriever.invoke(query)
            response = chain.invoke(query, config=cfg)
            memory.save_context(
                inputs = {"user" : query},
                outputs = {"assistant" : response}
            )

        # íƒ€ì´í•‘ íš¨ê³¼ë¡œ ì¶œë ¥
        typing_area = st.empty()  # ë¹ˆ ê³µê°„ì„ ë§Œë“¤ì–´ì„œ í…ìŠ¤íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•  ì¤€ë¹„
        typing_text = ""
        for char in response:
            typing_text += char
            typing_area.markdown(typing_text)  # í˜„ì¬ê¹Œì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥
            time.sleep(0.02)  # ê° ê¸€ìë¥¼ ì¶œë ¥í•  ë•Œë§ˆë‹¤ ì•½ê°„ì˜ ì§€ì—° (0.05ì´ˆ)

        with st.expander(":mag:**ì¶œì²˜ í™•ì¸**"):
            for doc in retrieved_docs:
                st.markdown(f"{doc.metadata['source'].split("/")[-1]}ì˜ {doc.metadata["page"] + 1}í˜ì´ì§€", help=doc.page_content)
            
        st.session_state.messages.append({"role": "assistant", "content": response})

    wait_for_all_tracers()
    logger.info(f"## íŠ¸ë ˆì´ìŠ¤ : {run_collector.traced_runs}")
    st.session_state.last_run = run_collector.traced_runs[0].id

@st.cache_data(ttl="2h", show_spinner=False)
def get_run_url(run_id):
    time.sleep(1)
    return client.read_run(run_id).url

if st.session_state.get("last_run"):
    run_url = get_run_url(st.session_state.last_run)
    st.sidebar.markdown(f"[LangSmith ì¶”ì ğŸ› ï¸]({run_url})")
    feedback = streamlit_feedback(
        feedback_type = "thumbs",
        optional_text_label = None,
        key = f"feedback_{st.session_state.last_run}"
    )
    if feedback:
        scores = {"ğŸ‘": 1, "ğŸ‘": 0}
        client.create_feedback(
            st.session_state.last_run,
            feedback["type"],
            score=scores[feedback["score"]],
            comment=query
        )
        st.toast("í”¼ë“œë°±ì„ ì €ì¥í•˜ì˜€ìŠµë‹ˆë‹¤.!", icon="ğŸ“")